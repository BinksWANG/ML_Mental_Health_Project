{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d843cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up MLflow tracking\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"mental-health-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f6d58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning function\n",
    "def clean_data(df):\n",
    "    # Fill missing values for 'Severity' and 'Consultation_History' with 'Unknown'\n",
    "    df['Severity'] = df['Severity'].fillna('Unknown')\n",
    "    df['Consultation_History'] = df['Consultation_History'].fillna('Unknown')\n",
    "\n",
    "    # Handle missing 'Stress_Level' by filling with 'Unknown'\n",
    "    df['Stress_Level'] = df['Stress_Level'].fillna('Unknown')\n",
    "\n",
    "    # Convert categorical columns to string types\n",
    "    categorical_columns = ['Gender', 'Occupation', 'Country', 'Mental_Health_Condition', 'Severity', 'Consultation_History', 'Stress_Level']\n",
    "    df[categorical_columns] = df[categorical_columns].astype(str)\n",
    "\n",
    "    # Convert categorical columns to numerical using LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_columns:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "    # Handle missing numerical values by filling with the median\n",
    "    df['Sleep_Hours'] = df['Sleep_Hours'].fillna(df['Sleep_Hours'].median())\n",
    "    df['Work_Hours'] = df['Work_Hours'].fillna(df['Work_Hours'].median())\n",
    "    df['Physical_Activity_Hours'] = df['Physical_Activity_Hours'].fillna(df['Physical_Activity_Hours'].median())\n",
    "\n",
    "    # Convert numerical columns to appropriate types\n",
    "    df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d49fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean data\n",
    "df = pd.read_csv('../data/mental_health_dataset.csv')\n",
    "df_cleaned = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b7516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target variable\n",
    "categorical = ['Gender', 'Occupation', 'Country', 'Mental_Health_Condition', 'Severity', 'Consultation_History', 'Stress_Level']\n",
    "numerical = ['Age', 'Sleep_Hours', 'Work_Hours', 'Physical_Activity_Hours']\n",
    "target = 'Mental_Health_Condition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c8ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test BEFORE vectorization (游릭 CHANGED)\n",
    "train_df, test_df = train_test_split(df_cleaned, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features into a single dictionary for DictVectorizer\n",
    "train_df['features'] = train_df[categorical + numerical].apply(lambda x: x.to_dict(), axis=1)\n",
    "test_df['features'] = test_df[categorical + numerical].apply(lambda x: x.to_dict(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04336298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target for modeling\n",
    "dv = DictVectorizer()\n",
    "\n",
    "X_train = dv.fit_transform(train_df['features'].tolist())  # 游릭 Fit on training data\n",
    "y_train = train_df[target].values\n",
    "\n",
    "X_test = dv.transform(test_df['features'].tolist())        # 游릭 Transform test data\n",
    "y_test = test_df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f07bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5488f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    # Prepare DMatrix for XGBoost\n",
    "    train_dmatrix = xgb.DMatrix(X_train, label=y_train)\n",
    "    test_dmatrix = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    best_params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'seed': 42,\n",
    "        'learning_rate': 0.9477136465696124,\n",
    "        'max_depth': 8,  \n",
    "        'min_child_weight': 4.94465806978135,\n",
    "        'reg_alpha': 0.007258751375563831,\n",
    "        'reg_lambda': 0.13869944407674337,\n",
    "    }\n",
    "\n",
    "    mlflow.set_tag(\"model\", \"xgboost-best\")\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train_dmatrix,\n",
    "        num_boost_round=10,\n",
    "        evals=[(test_dmatrix, 'validation')],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    y_pred = booster.predict(test_dmatrix)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    print(f\"游끠 Final XGBoost RMSE: {rmse}\")\n",
    "\n",
    "    # 游릭 Save preprocessor and booster\n",
    "    with open(\"models/preprocessor_xgb.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "    mlflow.log_artifact(\"models/preprocessor_xgb.b\", artifact_path=\"preprocessor\")\n",
    "    mlflow.xgboost.log_model(booster, artifact_path=\"models_mlflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604b4943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
